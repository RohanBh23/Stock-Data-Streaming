from minio import Minio
from io import BytesIO
import pandas as pd
from sklearn.preprocessing import StandardScaler
import json

def preprocess_stock_data(symbol, minio_bucket, minio_client):

    try:

        symbol_name = symbol[1:] if symbol.startswith('^') else symbol

        data_file = f"{symbol_name}/prices.json"
        response = minio_client.get_object(minio_bucket, data_file)

        # Read the content and inspect if it's valid JSON
        response_data = response.read()

        response_data_str = BytesIO(response_data).getvalue().decode('utf-8')
        # data = pd.read_json(BytesIO(response_data))

        parsed_json = json.loads(response_data_str)
        print(f"FAILED Parsed JSON: {parsed_json}")
        print("type : ", type(parsed_json))
        parsed_json = json.loads(parsed_json)
        print(f"Successful Parsed JSON: {parsed_json}")
        print("type : ", type(parsed_json))

        df = pd.DataFrame(parsed_json['timestamp'], parsed_json['indicators']['quote'][0]['high'])

        # if 'timestamp' in parsed_json and 'prices' in parsed_json:
        #     timestamps = parsed_json['timestamp']
        #     prices = parsed_json['prices']

        #     # Creating a DataFrame with two columns
        #     df = pd.DataFrame({
        #         'timestamp': timestamps,
        #         'prices': prices
        #     })

        #     print(df)
        # else:
        #     print("Required keys not found in the parsed JSON")

        if isinstance(parsed_json, dict):
            for key in parsed_json:
                # full_key = f"{prefix}.{key}" if prefix else key
                print(key)
                # print_json_keys(json_obj[key], full_key)

    except Exception as e:

        raise e



    # try:
    #     # Load JSON data from MinIO
    #     data_file = f"{symbol}/prices.json"
    #     response = minio_client.get_object(minio_bucket, data_file)

    #     # Read the content and inspect if it's valid JSON
    #     response_data = response.read()
    #     try:
    #         data = pd.read_json(BytesIO(response_data))
    #     except ValueError as e:
    #         print(f"Failed to parse JSON for {symbol}. Response data: {response_data}")
    #         raise e
        
    #     # Clean the data: fill missing values using forward fill
    #     cleaned_data = data.fillna(method="ffill")

    #     print("Cleaned 1")

    #     # Add Simple Moving Average (SMA) for 10 periods
    #     cleaned_data['sma_10'] = cleaned_data['close'].rolling(window=10).mean()

    #     print("Cleaned 2")

    #     # Standardize the features (SMA, Close Price, Volume)
    #     features = cleaned_data[['sma_10', 'close', 'volume']].fillna(0)  # Replace NaN with 0 for standardization
    #     scaler = StandardScaler()
    #     cleaned_data[['sma_10_scaled', 'close_scaled', 'volume_scaled']] = scaler.fit_transform(features)

    #     print("Cleaned 3")

    #     # Add lagged feature (previous dayâ€™s close price)
    #     cleaned_data['lag_1'] = cleaned_data['close'].shift(1)

    #     print("Cleaned 4")

    #     # Drop rows with NaN values generated by rolling and shifting operations (if necessary)
    #     cleaned_data = cleaned_data.dropna()
        

    #     # Display the result
    #     print(cleaned_data.head())

    #     # Save the preprocessed data back to MinIO as Parquet
    #     output_buffer = BytesIO()
    #     cleaned_data.to_parquet(output_buffer, index=False)
    #     output_buffer.seek(0)

    #     minio_client.put_object(minio_bucket, f"preprocessed/{symbol}.parquet", output_buffer, len(output_buffer.getvalue()))

    # except Exception as e:
    #     print(f"Error during preprocessing for symbol {symbol}: {str(e)}")
    #     raise
